{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c96482bf-3589-45fc-9e44-45cfe2b633ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, io, zipfile, json, time\n",
    "from datetime import datetime\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "RAW_DIR = \"../data/raw\"\n",
    "PROC_DIR = \"../data/processed\"\n",
    "os.makedirs(RAW_DIR, exist_ok=True)\n",
    "os.makedirs(PROC_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9ced10ad-7633-45bd-9d82-50a67d77c27b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded: ['JC-202201-citibike-tripdata.csv.zip', 'JC-202202-citibike-tripdata.csv.zip', 'JC-202203-citibike-tripdata.csv.zip', 'JC-202204-citibike-tripdata.csv.zip', 'JC-202205-citibike-tripdata.csv.zip', 'JC-202206-citibike-tripdata.csv.zip', 'JC-202207-citbike-tripdata.csv.zip', 'JC-202208-citibike-tripdata.csv.zip', 'JC-202209-citibike-tripdata.csv.zip', 'JC-202210-citibike-tripdata.csv.zip', 'JC-202211-citibike-tripdata.csv.zip', 'JC-202212-citibike-tripdata.csv.zip']\n",
      "Skipped (already present): []\n",
      "Missing months: []\n",
      "Files in raw: 13\n"
     ]
    }
   ],
   "source": [
    "# 1) DOWNLOAD MONTHLY ZIPS\n",
    "import os, time, requests\n",
    "\n",
    "BASE = \"https://s3.amazonaws.com/tripdata\"\n",
    "RAW_DIR = r\"C:\\Users\\moein\\anaconda3\\citi-bike-2022-weather\\data\\raw\"\n",
    "os.makedirs(RAW_DIR, exist_ok=True)\n",
    "\n",
    "months = [f\"2022{m:02d}\" for m in range(1, 13)]\n",
    "# Standard pattern + July fallback with the known typo\n",
    "def candidates(ym):\n",
    "    if ym == \"202207\":\n",
    "        return [\n",
    "            f\"JC-{ym}-citibike-tripdata.csv.zip\",  # preferred (try first)\n",
    "            f\"JC-{ym}-citbike-tripdata.csv.zip\",   # fallback (actual typo on S3)\n",
    "        ]\n",
    "    else:\n",
    "        return [f\"JC-{ym}-citibike-tripdata.csv.zip\"]\n",
    "\n",
    "def try_download(url, outpath):\n",
    "    with requests.get(url, stream=True, timeout=60) as r:\n",
    "        if r.status_code == 404:\n",
    "            return False\n",
    "        r.raise_for_status()\n",
    "        with open(outpath, \"wb\") as f:\n",
    "            for chunk in r.iter_content(1024*512):\n",
    "                if chunk:\n",
    "                    f.write(chunk)\n",
    "    return True\n",
    "\n",
    "downloaded, skipped, missing = [], [], []\n",
    "for ym in months:\n",
    "    ok = False\n",
    "    for fname in candidates(ym):\n",
    "        url = f\"{BASE}/{fname}\"\n",
    "        dst = os.path.join(RAW_DIR, fname)\n",
    "        if os.path.exists(dst):\n",
    "            skipped.append(fname)\n",
    "            ok = True\n",
    "            break\n",
    "        if try_download(url, dst):\n",
    "            downloaded.append(fname)\n",
    "            ok = True\n",
    "            time.sleep(0.4)\n",
    "            break\n",
    "    if not ok:\n",
    "        missing.append(ym)\n",
    "\n",
    "print(\"Downloaded:\", downloaded)\n",
    "print(\"Skipped (already present):\", skipped)\n",
    "print(\"Missing months:\", missing)\n",
    "print(\"Files in raw:\", len(os.listdir(RAW_DIR)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3303e295-4844-4d32-9d2b-2ab4e1859600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 895485 Cols: 13\n",
      "Saved: C:\\Users\\moein\\anaconda3\\citi-bike-2022-weather\\data\\processed\\citibike_2022_all.csv and (if supported) parquet.\n"
     ]
    }
   ],
   "source": [
    "# 2) CONCATENATE ALL INTO ONE DATAFRAME (no extraction)\n",
    "import os, zipfile, io\n",
    "import pandas as pd\n",
    "\n",
    "RAW_DIR = r\"C:\\Users\\moein\\anaconda3\\citi-bike-2022-weather\\data\\raw\"\n",
    "PROC_DIR = r\"C:\\Users\\moein\\anaconda3\\citi-bike-2022-weather\\data\\processed\"\n",
    "os.makedirs(PROC_DIR, exist_ok=True)\n",
    "\n",
    "# Helper to read a single ZIP -> DataFrame (robust to minor column differences)\n",
    "def read_zip_csv(zip_path):\n",
    "    with zipfile.ZipFile(zip_path) as z:\n",
    "        # Each zip has one CSV; grab it\n",
    "        names = [n for n in z.namelist() if n.lower().endswith(\".csv\")]\n",
    "        if not names:\n",
    "            return pd.DataFrame()\n",
    "        with z.open(names[0]) as f:\n",
    "            # Parse dates if present; ignore errors to avoid crashes\n",
    "            df = pd.read_csv(\n",
    "                io.TextIOWrapper(f, encoding=\"utf-8\"),\n",
    "                low_memory=False\n",
    "            )\n",
    "    return df\n",
    "\n",
    "# Load and union columns (outer concat)\n",
    "dfs = []\n",
    "for fname in sorted(os.listdir(RAW_DIR)):\n",
    "    if fname.lower().endswith(\".zip\") and fname.startswith(\"JC-2022\"):\n",
    "        path = os.path.join(RAW_DIR, fname)\n",
    "        df = read_zip_csv(path)\n",
    "        if not df.empty:\n",
    "            dfs.append(df)\n",
    "\n",
    "if not dfs:\n",
    "    raise RuntimeError(\"No CSVs loaded. Check your raw directory and filenames.\")\n",
    "\n",
    "# Outer concat to handle column mismatches across months\n",
    "all_df = pd.concat(dfs, axis=0, ignore_index=True, sort=False)\n",
    "\n",
    "# 3) LIGHT NORMALIZATION (optional but helpful)\n",
    "# Standardize likely datetime columns if they exist\n",
    "for col in [\"started_at\", \"ended_at\", \"starttime\", \"stoptime\", \"start_time\", \"end_time\"]:\n",
    "    if col in all_df.columns:\n",
    "        all_df[col] = pd.to_datetime(all_df[col], errors=\"coerce\")\n",
    "\n",
    "# Standardize member type column names (varies by year/version)\n",
    "membership_cols = [c for c in all_df.columns if \"member\" in c.lower() or \"usertype\" in c.lower()]\n",
    "if membership_cols:\n",
    "    # Pick the first as canonical\n",
    "    canon = membership_cols[0]\n",
    "    all_df.rename(columns={canon: \"member_type\"}, inplace=True)\n",
    "    # Optionally drop others to avoid duplicates\n",
    "    for c in membership_cols[1:]:\n",
    "        if c in all_df.columns:\n",
    "            all_df.drop(columns=c, inplace=True)\n",
    "\n",
    "# 4) SAVE\n",
    "out_csv = os.path.join(PROC_DIR, \"citibike_2022_all.csv\")\n",
    "out_parquet = os.path.join(PROC_DIR, \"citibike_2022_all.parquet\")\n",
    "all_df.to_csv(out_csv, index=False)\n",
    "try:\n",
    "    all_df.to_parquet(out_parquet, index=False)  # requires pyarrow or fastparquet\n",
    "except Exception as e:\n",
    "    print(\"Parquet save skipped (install pyarrow or fastparquet).\", e)\n",
    "\n",
    "print(\"Rows:\", len(all_df), \"Cols:\", len(all_df.columns))\n",
    "print(\"Saved:\", out_csv, \"and (if supported) parquet.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6d15d346-fc16-4dde-90a0-d20c06c0b168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date range: 2022-01-01 00:10:20 -> 2022-12-31 23:58:26\n",
      "ride_id non-null: 895485\n",
      "rideable_type non-null: 895485\n"
     ]
    }
   ],
   "source": [
    "# 5) QUICK SANITY CHECKS\n",
    "import pandas as pd\n",
    "all_df = pd.read_csv(r\"C:\\Users\\moein\\anaconda3\\citi-bike-2022-weather\\data\\processed\\citibike_2022_all.csv\")\n",
    "\n",
    "# Date coverage based on common columns if present\n",
    "date_cols = [c for c in [\"started_at\", \"starttime\", \"start_time\"] if c in all_df.columns]\n",
    "if date_cols:\n",
    "    dcol = date_cols[0]\n",
    "    all_df[dcol] = pd.to_datetime(all_df[dcol], errors=\"coerce\")\n",
    "    print(\"Date range:\", all_df[dcol].min(), \"->\", all_df[dcol].max())\n",
    "\n",
    "# Basic stats\n",
    "for c in [\"ride_id\", \"tripduration\", \"duration\", \"rideable_type\"]:\n",
    "    if c in all_df.columns:\n",
    "        print(c, \"non-null:\", all_df[c].notna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e038f2-9df6-432b-9548-1fe0e93e456f",
   "metadata": {},
   "source": [
    "### Combining Monthly Citi Bike Data\n",
    "\n",
    "The raw data for 2022 is provided as 12 separate monthly ZIP files, each containing a single CSV.  \n",
    "Since the schema can vary slightly across months (e.g., different column names or additional fields),  \n",
    "I used **`pd.concat(..., sort=False)` with `ignore_index=True`** to create one unified DataFrame.  \n",
    "\n",
    "This approach is effectively an **outer join on columns** across all months:  \n",
    "- If a column exists in every month, the values align correctly.  \n",
    "- If a column is missing from some months, those entries are automatically filled with `NaN`.  \n",
    "- This ensures no data is lost and all available fields are preserved for downstream analysis.  \n",
    "\n",
    "After concatenation, I applied some light normalization (e.g., parsing datetime fields and standardizing membership column names)  \n",
    "so that the combined dataset is consistent and ready for merging later with external weather data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b9d96b90-e10c-4cb1-aa22-854bdc9803dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(        date  avg_temp_c\n",
       " 0 2022-01-01        11.6\n",
       " 1 2022-01-02        11.4\n",
       " 2 2022-01-03         1.4\n",
       " 3 2022-01-04        -2.7\n",
       " 4 2022-01-05         3.2,\n",
       " (365, 2))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pull LaGuardia daily weather (2022) via NOAA API\n",
    "\n",
    "import os, json, requests\n",
    "from datetime import datetime\n",
    "\n",
    "TOKEN = os.getenv(\"NOAA_TOKEN\") or \"pXfcUANbqHxxlaXzZjnEMAqEiQukZWHh\"\n",
    "\n",
    "BASE = \"https://www.ncdc.noaa.gov/cdo-web/api/v2/data\"\n",
    "params_tavg = {\n",
    "    \"datasetid\":\"GHCND\",\n",
    "    \"datatypeid\":\"TAVG\",\n",
    "    \"stationid\":\"GHCND:USW00014732\",\n",
    "    \"startdate\":\"2022-01-01\",\n",
    "    \"enddate\":\"2022-12-31\",\n",
    "    \"limit\":1000\n",
    "}\n",
    "headers = {\"token\": TOKEN}\n",
    "\n",
    "r = requests.get(BASE, params=params_tavg, headers=headers)\n",
    "r.raise_for_status()\n",
    "d = r.json()\n",
    "tavg_rows = d.get(\"results\", [])\n",
    "\n",
    "# If TAVG sparse, pull TMIN+TMAX and compute\n",
    "if not tavg_rows or len(tavg_rows) < 300:\n",
    "    params_tmin = params_tavg.copy(); params_tmin[\"datatypeid\"]=\"TMIN\"\n",
    "    params_tmax = params_tavg.copy(); params_tmax[\"datatypeid\"]=\"TMAX\"\n",
    "    rmin = requests.get(BASE, params=params_tmin, headers=headers); rmin.raise_for_status()\n",
    "    rmax = requests.get(BASE, params=params_tmax, headers=headers); rmax.raise_for_status()\n",
    "    tmin = {(it[\"date\"][:10]): it[\"value\"] for it in rmin.json().get(\"results\", [])}\n",
    "    tmax = {(it[\"date\"][:10]): it[\"value\"] for it in rmax.json().get(\"results\", [])}\n",
    "    keys = sorted(set(tmin) | set(tmax))\n",
    "    weather = pd.DataFrame({\n",
    "        \"date\": pd.to_datetime(keys),\n",
    "        # NOAA stores temps in tenths of °C\n",
    "        \"avg_temp_c\": [((tmin.get(k) + tmax.get(k))/2)/10.0 if (tmin.get(k) is not None and tmax.get(k) is not None) else None for k in keys]\n",
    "    })\n",
    "else:\n",
    "    # Build from TAVG directly\n",
    "    dates = [it[\"date\"][:10] for it in tavg_rows]\n",
    "    vals  = [it[\"value\"]/10.0 for it in tavg_rows]  # tenths °C → °C\n",
    "    weather = pd.DataFrame({\n",
    "        \"date\": pd.to_datetime(dates),\n",
    "        \"avg_temp_c\": vals\n",
    "    })\n",
    "\n",
    "weather = weather.sort_values(\"date\").dropna(subset=[\"avg_temp_c\"])\n",
    "weather.to_csv(os.path.join(PROC_DIR, \"lga_weather_2022.csv\"), index=False)\n",
    "weather.head(), weather.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "74cf2cb1-1287-4895-840b-389e6986d2ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: C:\\Users\\moein\\anaconda3\\citi-bike-2022-weather\\data\\processed\\citibike_2022_daily_with_weather.csv\n",
      "         date  rides  member_share  avg_temp_c\n",
      "0  2022-01-01    592      0.543919        11.6\n",
      "1  2022-01-02   1248      0.584936        11.4\n",
      "2  2022-01-03    832      0.772837         1.4\n",
      "3  2022-01-04    934      0.776231        -2.7\n",
      "4  2022-01-05    914      0.750547         3.2\n",
      "Shape: (365, 4)\n"
     ]
    }
   ],
   "source": [
    "# Merge daily trips with weather & export\n",
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "PROC_DIR = r\"C:\\Users\\moein\\anaconda3\\citi-bike-2022-weather\\data\\processed\"\n",
    "cb_path = os.path.join(PROC_DIR, \"citibike_2022_all.csv\")\n",
    "wx_path = os.path.join(PROC_DIR, \"lga_weather_2022.csv\")\n",
    "\n",
    "cb = pd.read_csv(cb_path, low_memory=False)\n",
    "wx = pd.read_csv(wx_path, parse_dates=[\"date\"])\n",
    "wx[\"date\"] = wx[\"date\"].dt.date\n",
    "\n",
    "# 1) pick a start datetime column and derive a date\n",
    "start_candidates = [\"started_at\", \"starttime\", \"start_time\"]\n",
    "start_col = next((c for c in start_candidates if c in cb.columns), None)\n",
    "if start_col is None:\n",
    "    raise ValueError(\"No start datetime column found in CitiBike data.\")\n",
    "cb[start_col] = pd.to_datetime(cb[start_col], errors=\"coerce\")\n",
    "cb[\"date\"] = cb[start_col].dt.date\n",
    "\n",
    "# 2) unify duration if available (seconds → minutes)\n",
    "if \"tripduration\" in cb.columns:\n",
    "    cb[\"duration_min\"] = cb[\"tripduration\"] / 60.0\n",
    "elif \"duration\" in cb.columns:\n",
    "    cb[\"duration_min\"] = cb[\"duration\"] / 60.0\n",
    "\n",
    "# 3) compute daily metrics (feel free to add more later)\n",
    "def member_ratio(series):\n",
    "    if series.isna().all():\n",
    "        return None\n",
    "    s = series.astype(str).str.lower()\n",
    "    # treat 'member' or 'subscriber' as members; adjust if your schema differs\n",
    "    return ((s.str.contains(\"member\") | s.str.contains(\"subscriber\")).sum()) / len(s)\n",
    "\n",
    "agg_dict = {\n",
    "    \"date\": \"size\",  # count rides\n",
    "}\n",
    "daily = cb.groupby(\"date\", as_index=False).agg(rides=(\"date\", \"size\"))\n",
    "\n",
    "if \"duration_min\" in cb.columns:\n",
    "    daily = cb.groupby(\"date\", as_index=False).agg(\n",
    "        rides=(\"date\", \"size\"),\n",
    "        avg_duration_min=(\"duration_min\", \"mean\")\n",
    "    )\n",
    "\n",
    "if \"member_type\" in cb.columns:\n",
    "    tmp = cb.groupby(\"date\")[\"member_type\"].apply(member_ratio).reset_index(name=\"member_share\")\n",
    "    daily = daily.merge(tmp, on=\"date\", how=\"left\")\n",
    "\n",
    "# 4) merge with weather on date\n",
    "merged = daily.merge(wx, on=\"date\", how=\"left\")\n",
    "\n",
    "# 5) save outputs\n",
    "out_daily = os.path.join(PROC_DIR, \"citibike_2022_daily_with_weather.csv\")\n",
    "merged.to_csv(out_daily, index=False)\n",
    "\n",
    "print(\"Saved:\", out_daily)\n",
    "print(merged.head())\n",
    "print(\"Shape:\", merged.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b1bac273-5664-423a-8229-36adebbd3b7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: C:\\Users\\moein\\anaconda3\\citi-bike-2022-weather\\data\\processed\\citibike_2022_trips_with_weather.csv Rows: 895485\n"
     ]
    }
   ],
   "source": [
    "# Trip-level merge (very large; only if we really need per-ride temps)\n",
    "\n",
    "import os, pandas as pd\n",
    "\n",
    "PROC_DIR = r\"C:\\Users\\moein\\anaconda3\\citi-bike-2022-weather\\data\\processed\"\n",
    "cb = pd.read_csv(os.path.join(PROC_DIR, \"citibike_2022_all.csv\"), low_memory=False)\n",
    "wx = pd.read_csv(os.path.join(PROC_DIR, \"lga_weather_2022.csv\"), parse_dates=[\"date\"])\n",
    "wx[\"date\"] = wx[\"date\"].dt.date\n",
    "\n",
    "start_candidates = [\"started_at\", \"starttime\", \"start_time\"]\n",
    "start_col = next((c for c in start_candidates if c in cb.columns), None)\n",
    "cb[start_col] = pd.to_datetime(cb[start_col], errors=\"coerce\")\n",
    "cb[\"date\"] = cb[start_col].dt.date\n",
    "\n",
    "cb_merged = cb.merge(wx, on=\"date\", how=\"left\")\n",
    "out_trips = os.path.join(PROC_DIR, \"citibike_2022_trips_with_weather.csv\")\n",
    "cb_merged.to_csv(out_trips, index=False)\n",
    "print(\"Saved:\", out_trips, \"Rows:\", len(cb_merged))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3165c903-8d4c-40ad-a842-a81e806e4c75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (20th_century)",
   "language": "python",
   "name": "20th_century"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
